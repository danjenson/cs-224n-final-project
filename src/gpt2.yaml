---
dataset:
  path: "./tds"
  translate:
    source: "nlc"
    target: "cmd_templated"
model:
  task: "causal"
  checkpoint: "gpt2"
training:
  output_dir: "./results"
  overwrite_output_dir: True
  num_train_epochs: 25
  per_device_train_batch_size: 10
  per_device_eval_batch_size: 10
  eval_steps: 100
  save_steps: 10000
  warmup_steps: 100
  logging_steps: 100
  prediction_loss_only: True
output_path: "./results/gpt2"
