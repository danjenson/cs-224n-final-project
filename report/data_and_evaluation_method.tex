\subsection{Data}
The dataset we used is from the
``\href{https://nlc2cmd.us-east.mybluemix.net/}{The NLC2CMD Competition},''
consisting of 10,000 parallel translations of English (named as the
``invocation'') and bash command (named as the ``cmd''), and one example is
shown as follows:

\begin{verbatim}
invocation: Assign permissions 755 to directories in the current directory tree
cmd: find . -type d -print0 | xargs -0 chmod 755
\end{verbatim}


Instead of a single task, most of the invocations involve a sequence of
different tasks, and consequently the bash commands are usually in the form of
long pipelines. In addition, since the bash commands contain identifiers, such
as directory paths, file names, and permissions, a templatization scheme has
been used by casting the shell commands into the corresponding abstract syntax
trees (AST), replacing the identifiers and then casting the AST back to
commands. After this step, the
command we saw in the previous example were templatized into
\begin{verbatim}
templatized cmd: find Path -type d -print0 | xargs -0 -I chmod Permission
\end{verbatim}
for easier generalization during training.

The dataset was split into the training and test sets with a ratio of 0.98 : 0.02. The invocations and templatized commands must be tokenized by the tokenizer associated with each model. and the outputs of different tokenizers are different. Print out the output of the tokenizer (followed by a decoding process to translate the tokens back to words) and we can find that the above example has been tokenized in the form of
\begin{verbatim}
<s>Assign permissions 755 to directories in the current directory 
tree</s></s>find Path -type d -print0 | xargs -0 -I chmod Permission</s>
\end{verbatim}
for the BART tokenizer, and in the form of
\begin{verbatim}
Assign permissions 755 to directories in the current directory 
tree</s> find Path -type d -print0 | xargs -0 -I chmod Permission</s>
\end{verbatim}
by the T5 tokenizer.

For the causal language model GPT2, additional preprocessing much be
performed. We introduced special tokens to separate the invocations and
commands, and assemble them in the form of

\begin{verbatim}
<bos_token> <source_token> <invocation> <target_token>

                                              <templatized cmd> <eos_token> 
\end{verbatim}
before fed them into the GPT-2 tokenizer. For the example above, the output of the GPT-2 tokenizer is
\begin{verbatim}
<|endoftext|> <|source|> Assign permissions 755 to directories in the current
directory tree <|target|> find Path -type d -print0 | xargs -0 -I chmod 
Permission <|endoftext|>

\end{verbatim}


\subsection{Evaluation method}
The standard cross-entropy loss function was used to trained the models. But a more robust metric measuring the execution accuracy of the model predictions must be used, and we used the metric defined by the competition as
\begin{align*}
	S(p) & =\sum_{i\in[1,T]}\frac{1}{T}\times\left(
	\mathbb{I}[U(c)_i=U(C)i]\times\frac{1}{2}\left(
		1+\frac{1}{N}\left(X\right)\right) -\mathbb{I}[U(c)_i\ne U(C)_i]
	\right)
\end{align*}
where $U(x)$ is a sequence of bash utilities in a command $x$, $c$ is the
predicted bash command and $C$ is the ground truth bash command.
Apart measuring whether the utilities in the two commands match, an additional variable $X$ has been introduced to measure whether the flags associated with each utility match or not, as
\begin{equation*}
	X = 2\times
	|F(U(c)_i)\cap F(U(C)_i)| - |F(U(c)_i)\cup F(U(C)_i)|
\end{equation*}
where $F(x)$ refers to
the set of bash flags in a command $x$. $T$ is the maximum length between
$U(c)$ and $U(C)$ while $N$ is the maximum size between $F(c)$ and $F(C)$. Since the order of flags does not matter, set operations have been used here.

This is a very strict metric penalizing for both incorrect and extra bash utilities and flags. The return value of the metric is between -1.0 and 1.0, and only a command which produces exactly the same execution result as the ground truth one can get a score of 1.0.