\section{Introduction}
Bash, the Unix command language, has long been used to interact with computers
universally, expressively and efficiently.  However, due to the existence of
numerous bash utilities (e.g. ``find'', ``cd'', ``mkdir'') and flags (e.g.
``-f'', ``-r'' ), novitiates often find the terminal interface perplexing and
are quickly overwhelmed by the syntax of Bash commands. Even experienced
engineers frequently consult man-pages, online documentation, and online forms
like Stack Overflow to learn about the particulars of various commands. This
project aims to ease those burdens on new and experienced users alike, and
develop tools to generate Bash commands from natural language. We want to
provide a NLI (Natural Language Interface) enabling people to interact with
computers through natural languages, and make the programming resources more
accessible to the public.

However, translating natural language into bash can be challenging: different
users have different ways to express logical statement in natural language; a
single task may involve pipelines of different utilities, and the order of
these utilities matters; one utility can be associated with multiple flags, and
different flags can be switched; there are a lot of identifiers like specific
paths or file names in bash commands; and finally, the bash commands must be perfectly correct before
they can be executed in terminals.

In this work, we used the data from the NeurIPS 2020 NLC2CMD Challenge, and
experimented with several transformer models, including GPT-2, BART, and T5, as
well as different tokenization and postprocessing schemes to generate bash
commands from natural language. We evaluated the model performance from both
the training loss and a specific metric measuring how similar two Bash commands
are, and compared our models with the baseline model provided in the
competition.


\section{Related Work}
Code generation is a variant of semantic parsing, and a number of research
works have been published in this area. One of the earliest and most successful
studies was conducted to translate the natural language to SQL query, and Zhong
et al. (2017) \cite{zhong2017seq2sql} proposed a deep augmented pointer network
and achieved an execution accuracy of 60\% when combined with reinforcement
learning. However, it must be taken into consideration that SQL is more like a
domain specific language with a much simpler syntax.

For high level programming language generation, there are recent attempts to
translate well structured natural language input into Java or Python.  Ling et
al. (2016) \cite{ling2016latent} proposed a generative mode with a multiple
pointer network to generate code from texts in Trading Card Games, and such
input language is rather formal. A more robust syntax-based model has been
developed by Yin and Neubig (2017) \cite{yin2017syntactic} and tested on the
same dataset, but the result was only found to be equally good. Rahit et al.
(2019) \cite{rahit2019machine} used recurrent neural network (RNN) and
long-short term memory (LSTM) to build their model and reported an accuracy as
high as 74\% when the input was prepared in a format closer to pseudo code with
keywords such as “define” and “if-else”.

In the specific domain of Bash command generation, Lin et al. (2018)
\cite{lin2018nl2bash} modified the seq2seq model by adding gated recurrent
units (GRU) and RNN cells, and introducing a copying mechanism. The model was
evaluated manually by people, rather than by an objective metric, and the accuracy was reported to be 0.29. Fu et al. (2021) \cite{Fu2021ATransform} built a transformer model combined with beam searching and won the NLC2CMD Challenge competition. They also tested different models and concluded that transformer-based models could significantly outperform the RNN-based models.
% TODO: Yingxaio -- what about the competition winner? Ethan said we should
% definitely include info from that during OH